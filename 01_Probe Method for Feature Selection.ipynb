{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# How to select features using Probe Method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What is the Probe Method for Feature Selection?\n",
    "\n",
    "The Probe method is a highly intuitive approach to feature selection. The idea is to introduce a random feature to the dataset and train a machine learning model. This random feature is understand to have no useful information to predict the Y. After training the ML model, extract the feature importances.\n",
    "\n",
    "The features that has lower feature importance scores compared to the random variable, are considered as weak and useless. \n",
    "\n",
    "Drop the weak features. \n",
    "\n",
    "Then reintroduce the random feature into the dataset and retrain the model to extract the feature importance scores. Again find out the variables that are weaker than the random variable. Repeat this process until you are left with zero variables to drop.\n",
    "\n",
    "This is exactly how the probe method works. This is extremely intuitive, so it is easy to explain to your clients. \n",
    "\n",
    "\n",
    "__Which  algorithm to use to train the model in Probe method?__\n",
    "\n",
    "Good question. It does not really matter. You can either go for the traditional logistic regression based model or use the algorithm that you are going to use to ultimately train your model.\n",
    "\n",
    "\n",
    "## Advantages of Feature Selection\n",
    "\n",
    "- Lesser variables implies shorter model training and inference\n",
    "- Easy to interpret.\n",
    "- Easier to train models on large datasets.\n",
    "- More reliable model perforance, since the poor variables are moved out.\n",
    "\n",
    "## Install Feature Engine Package\n",
    "\n",
    "The probe method is readily implemented in the `feature-engine` package. So, let's use that for easy use.\n",
    "\n",
    "First let's install `fearure-engine` package."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature Engine Version:  1.6.2\n"
     ]
    }
   ],
   "source": [
    "# !pip install feature-engine==1.6.2\n",
    "!python -c \"import feature_engine; print('Feature Engine Version: ', feature_engine.__version__)\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Packages\n",
    "\n",
    "Mainly importing `Logistic Regression` and `ProbeSelectionSelection`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "from sklearn import datasets \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Probe Method from FeatureEngine\n",
    "from feature_engine.selection import ProbeFeatureSelection\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset and prepare train and test\n",
    "\n",
    "Load dataset and train test split it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean radius</th>\n",
       "      <th>mean texture</th>\n",
       "      <th>mean perimeter</th>\n",
       "      <th>mean area</th>\n",
       "      <th>mean smoothness</th>\n",
       "      <th>mean compactness</th>\n",
       "      <th>mean concavity</th>\n",
       "      <th>mean concave points</th>\n",
       "      <th>mean symmetry</th>\n",
       "      <th>mean fractal dimension</th>\n",
       "      <th>...</th>\n",
       "      <th>worst radius</th>\n",
       "      <th>worst texture</th>\n",
       "      <th>worst perimeter</th>\n",
       "      <th>worst area</th>\n",
       "      <th>worst smoothness</th>\n",
       "      <th>worst compactness</th>\n",
       "      <th>worst concavity</th>\n",
       "      <th>worst concave points</th>\n",
       "      <th>worst symmetry</th>\n",
       "      <th>worst fractal dimension</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>9.029</td>\n",
       "      <td>17.33</td>\n",
       "      <td>58.79</td>\n",
       "      <td>250.5</td>\n",
       "      <td>0.10660</td>\n",
       "      <td>0.14130</td>\n",
       "      <td>0.31300</td>\n",
       "      <td>0.04375</td>\n",
       "      <td>0.2111</td>\n",
       "      <td>0.08046</td>\n",
       "      <td>...</td>\n",
       "      <td>10.31</td>\n",
       "      <td>22.65</td>\n",
       "      <td>65.50</td>\n",
       "      <td>324.7</td>\n",
       "      <td>0.14820</td>\n",
       "      <td>0.43650</td>\n",
       "      <td>1.25200</td>\n",
       "      <td>0.17500</td>\n",
       "      <td>0.4228</td>\n",
       "      <td>0.11750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>21.090</td>\n",
       "      <td>26.57</td>\n",
       "      <td>142.70</td>\n",
       "      <td>1311.0</td>\n",
       "      <td>0.11410</td>\n",
       "      <td>0.28320</td>\n",
       "      <td>0.24870</td>\n",
       "      <td>0.14960</td>\n",
       "      <td>0.2395</td>\n",
       "      <td>0.07398</td>\n",
       "      <td>...</td>\n",
       "      <td>26.68</td>\n",
       "      <td>33.48</td>\n",
       "      <td>176.50</td>\n",
       "      <td>2089.0</td>\n",
       "      <td>0.14910</td>\n",
       "      <td>0.75840</td>\n",
       "      <td>0.67800</td>\n",
       "      <td>0.29030</td>\n",
       "      <td>0.4098</td>\n",
       "      <td>0.12840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>63</th>\n",
       "      <td>9.173</td>\n",
       "      <td>13.86</td>\n",
       "      <td>59.20</td>\n",
       "      <td>260.9</td>\n",
       "      <td>0.07721</td>\n",
       "      <td>0.08751</td>\n",
       "      <td>0.05988</td>\n",
       "      <td>0.02180</td>\n",
       "      <td>0.2341</td>\n",
       "      <td>0.06963</td>\n",
       "      <td>...</td>\n",
       "      <td>10.01</td>\n",
       "      <td>19.23</td>\n",
       "      <td>65.59</td>\n",
       "      <td>310.1</td>\n",
       "      <td>0.09836</td>\n",
       "      <td>0.16780</td>\n",
       "      <td>0.13970</td>\n",
       "      <td>0.05087</td>\n",
       "      <td>0.3282</td>\n",
       "      <td>0.08490</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>248</th>\n",
       "      <td>10.650</td>\n",
       "      <td>25.22</td>\n",
       "      <td>68.01</td>\n",
       "      <td>347.0</td>\n",
       "      <td>0.09657</td>\n",
       "      <td>0.07234</td>\n",
       "      <td>0.02379</td>\n",
       "      <td>0.01615</td>\n",
       "      <td>0.1897</td>\n",
       "      <td>0.06329</td>\n",
       "      <td>...</td>\n",
       "      <td>12.25</td>\n",
       "      <td>35.19</td>\n",
       "      <td>77.98</td>\n",
       "      <td>455.7</td>\n",
       "      <td>0.14990</td>\n",
       "      <td>0.13980</td>\n",
       "      <td>0.11250</td>\n",
       "      <td>0.06136</td>\n",
       "      <td>0.3409</td>\n",
       "      <td>0.08147</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>10.170</td>\n",
       "      <td>14.88</td>\n",
       "      <td>64.55</td>\n",
       "      <td>311.9</td>\n",
       "      <td>0.11340</td>\n",
       "      <td>0.08061</td>\n",
       "      <td>0.01084</td>\n",
       "      <td>0.01290</td>\n",
       "      <td>0.2743</td>\n",
       "      <td>0.06960</td>\n",
       "      <td>...</td>\n",
       "      <td>11.02</td>\n",
       "      <td>17.45</td>\n",
       "      <td>69.86</td>\n",
       "      <td>368.6</td>\n",
       "      <td>0.12750</td>\n",
       "      <td>0.09866</td>\n",
       "      <td>0.02168</td>\n",
       "      <td>0.02579</td>\n",
       "      <td>0.3557</td>\n",
       "      <td>0.08020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     mean radius  mean texture  mean perimeter  mean area  mean smoothness  \\\n",
       "68         9.029         17.33           58.79      250.5          0.10660   \n",
       "181       21.090         26.57          142.70     1311.0          0.11410   \n",
       "63         9.173         13.86           59.20      260.9          0.07721   \n",
       "248       10.650         25.22           68.01      347.0          0.09657   \n",
       "60        10.170         14.88           64.55      311.9          0.11340   \n",
       "\n",
       "     mean compactness  mean concavity  mean concave points  mean symmetry  \\\n",
       "68            0.14130         0.31300              0.04375         0.2111   \n",
       "181           0.28320         0.24870              0.14960         0.2395   \n",
       "63            0.08751         0.05988              0.02180         0.2341   \n",
       "248           0.07234         0.02379              0.01615         0.1897   \n",
       "60            0.08061         0.01084              0.01290         0.2743   \n",
       "\n",
       "     mean fractal dimension  ...  worst radius  worst texture  \\\n",
       "68                  0.08046  ...         10.31          22.65   \n",
       "181                 0.07398  ...         26.68          33.48   \n",
       "63                  0.06963  ...         10.01          19.23   \n",
       "248                 0.06329  ...         12.25          35.19   \n",
       "60                  0.06960  ...         11.02          17.45   \n",
       "\n",
       "     worst perimeter  worst area  worst smoothness  worst compactness  \\\n",
       "68             65.50       324.7           0.14820            0.43650   \n",
       "181           176.50      2089.0           0.14910            0.75840   \n",
       "63             65.59       310.1           0.09836            0.16780   \n",
       "248            77.98       455.7           0.14990            0.13980   \n",
       "60             69.86       368.6           0.12750            0.09866   \n",
       "\n",
       "     worst concavity  worst concave points  worst symmetry  \\\n",
       "68           1.25200               0.17500          0.4228   \n",
       "181          0.67800               0.29030          0.4098   \n",
       "63           0.13970               0.05087          0.3282   \n",
       "248          0.11250               0.06136          0.3409   \n",
       "60           0.02168               0.02579          0.3557   \n",
       "\n",
       "     worst fractal dimension  \n",
       "68                   0.11750  \n",
       "181                  0.12840  \n",
       "63                   0.08490  \n",
       "248                  0.08147  \n",
       "60                   0.08020  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "# Load data\n",
    "bc = datasets.load_breast_cancer(as_frame=True)\n",
    "X = bc.data\n",
    "y = bc.target\n",
    "features = bc.feature_names\n",
    "\n",
    "\n",
    "# Split data into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probe Feature Selection\n",
    "\n",
    "Apply Probe Feature Selection method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "sel = ProbeFeatureSelection(\n",
    "    estimator=LogisticRegression(),\n",
    "    scoring=\"roc_auc\",\n",
    "    n_probes=1,\n",
    "    distribution=\"uniform\",\n",
    "    cv=3,\n",
    "    random_state=150,\n",
    ")\n",
    "\n",
    "X_tr = sel.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract Feature Importances from the Probe Method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'worst radius': 1.022,\n",
       " 'mean radius': 0.996,\n",
       " 'worst concavity': 0.679,\n",
       " 'worst compactness': 0.552,\n",
       " 'texture error': 0.459,\n",
       " 'worst texture': 0.375,\n",
       " 'mean perimeter': 0.282,\n",
       " 'worst perimeter': 0.244,\n",
       " 'mean concavity': 0.243,\n",
       " 'mean texture': 0.236,\n",
       " 'worst concave points': 0.202,\n",
       " 'perimeter error': 0.19,\n",
       " 'mean compactness': 0.174,\n",
       " 'worst symmetry': 0.162,\n",
       " 'uniform_probe_0': 0.107,\n",
       " 'mean concave points': 0.105,\n",
       " 'area error': 0.101,\n",
       " 'worst smoothness': 0.069,\n",
       " 'worst fractal dimension': 0.055,\n",
       " 'mean symmetry': 0.05,\n",
       " 'concavity error': 0.048,\n",
       " 'mean smoothness': 0.038,\n",
       " 'radius error': 0.037,\n",
       " 'compactness error': 0.035,\n",
       " 'mean area': 0.016,\n",
       " 'worst area': 0.016,\n",
       " 'concave points error': 0.013,\n",
       " 'symmetry error': 0.012,\n",
       " 'mean fractal dimension': 0.01,\n",
       " 'fractal dimension error': 0.003,\n",
       " 'smoothness error': 0.003}"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(round(sel.feature_importances_, 3))\n",
    "{k: round(v, 3) for k, v in sorted(sel.feature_importances_.items(), key=lambda item: -item[1])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __What Features to Drop?__\n",
    "\n",
    "We can safely drop the features that has lesser importance score comparatively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean area',\n",
       " 'mean smoothness',\n",
       " 'mean concave points',\n",
       " 'mean symmetry',\n",
       " 'mean fractal dimension',\n",
       " 'radius error',\n",
       " 'area error',\n",
       " 'smoothness error',\n",
       " 'compactness error',\n",
       " 'concavity error',\n",
       " 'concave points error',\n",
       " 'symmetry error',\n",
       " 'fractal dimension error',\n",
       " 'worst area',\n",
       " 'worst smoothness',\n",
       " 'worst fractal dimension']"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.features_to_drop_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Probe Feature Selection using RandomForest\n",
    "\n",
    "Let's understand how Probe Selection performs on a RandomForest model. Is it giving the same set of feature?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfprobe = ProbeFeatureSelection(\n",
    "    estimator=RandomForestClassifier(),\n",
    "    scoring=\"roc_auc\",\n",
    "    n_probes=1,\n",
    "    distribution=\"uniform\",\n",
    "    cv=3,\n",
    "    random_state=150,\n",
    ")\n",
    "\n",
    "X_rf = rfprobe.fit_transform(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'worst perimeter': 0.135,\n",
       " 'worst concave points': 0.126,\n",
       " 'worst area': 0.097,\n",
       " 'worst radius': 0.087,\n",
       " 'mean concave points': 0.081,\n",
       " 'mean perimeter': 0.062,\n",
       " 'mean concavity': 0.059,\n",
       " 'mean radius': 0.055,\n",
       " 'area error': 0.05,\n",
       " 'worst concavity': 0.042,\n",
       " 'mean area': 0.041,\n",
       " 'worst texture': 0.017,\n",
       " 'worst compactness': 0.017,\n",
       " 'perimeter error': 0.015,\n",
       " 'mean texture': 0.015,\n",
       " 'radius error': 0.014,\n",
       " 'worst smoothness': 0.012,\n",
       " 'worst symmetry': 0.011,\n",
       " 'mean compactness': 0.009,\n",
       " 'concavity error': 0.007,\n",
       " 'worst fractal dimension': 0.007,\n",
       " 'mean smoothness': 0.006,\n",
       " 'smoothness error': 0.005,\n",
       " 'compactness error': 0.005,\n",
       " 'fractal dimension error': 0.004,\n",
       " 'texture error': 0.004,\n",
       " 'symmetry error': 0.004,\n",
       " 'mean fractal dimension': 0.004,\n",
       " 'concave points error': 0.004,\n",
       " 'mean symmetry': 0.003,\n",
       " 'uniform_probe_0': 0.002}"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(round(rfprobe.feature_importances_, 3))\n",
    "{k: round(v, 3) for k, v in sorted(rfprobe.feature_importances_.items(), key=lambda item: -item[1])}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Features to Drop according to Random Forest based Probe method__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['mean area',\n",
       " 'mean smoothness',\n",
       " 'mean concave points',\n",
       " 'mean symmetry',\n",
       " 'mean fractal dimension',\n",
       " 'radius error',\n",
       " 'area error',\n",
       " 'smoothness error',\n",
       " 'compactness error',\n",
       " 'concavity error',\n",
       " 'concave points error',\n",
       " 'symmetry error',\n",
       " 'fractal dimension error',\n",
       " 'worst area',\n",
       " 'worst smoothness',\n",
       " 'worst fractal dimension']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sel.features_to_drop_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The list of features to drop in both methods seem to match.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlenv3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
